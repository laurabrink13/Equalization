{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import commpy as cp\n",
    "import scipy.signal as sig\n",
    "import scipy.linalg as la\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def modulate(data, mod_scheme='BPSK', demod=False):\n",
    "    \"\"\"  1. Modulates (or demodulates) data according to the modulation scheme \"\"\"\n",
    "    mod_schemes = ['BPSK', 'QPSK']\n",
    "    data = data.flatten()\n",
    "    if mod_scheme not in mod_schemes:\n",
    "        raise ValueError('Unknown modulation scheme, please choose from: '+ ' '.join(mod_schemes))\n",
    "    elif mod_scheme == 'QPSK':\n",
    "        modulator = cp.modulation.QAMModem(4)\n",
    "        if demod:\n",
    "            return modulator.demodulate(data, \"hard\")\n",
    "        return modulator.modulate(data)\n",
    "    elif mod_scheme == 'BPSK':\n",
    "        def bpsk_one(x):\n",
    "            if demod:\n",
    "                return 0 if x < 0 else 1\n",
    "            return -1 if x==0 else 1\n",
    "        bpsk = np.vectorize(bpsk_one)\n",
    "        return bpsk(data)\n",
    "\n",
    "def apply_channel(signal, channel_function):\n",
    "    \"\"\"  2. Convolves signal with channel_function \"\"\"\n",
    "    channel_output = sig.convolve(signal, channel_function, mode='full') # convolve input complex data with the channel transfer function\n",
    "    return channel_output\n",
    "\n",
    "def add_awgn_noise(signal, SNR_dB):\n",
    "    \"\"\"  3. Adds AWGN noise vector to signal  \n",
    "            to generate a resulting signal vector y of specified SNR in dB\n",
    "    \"\"\"\n",
    "    L=len(signal)\n",
    "    SNR = 10**(SNR_dB/10.0) #SNR to linear scale\n",
    "    Esym=np.sum(np.square(np.abs(signal)))/L #Calculate actual symbol energy\n",
    "    N0=Esym/SNR; #Find the noise spectral density\n",
    "    if(isinstance(signal[0], complex)):\n",
    "        noiseSigma=np.sqrt(N0/2.0)#Standard deviation for AWGN Noise when x is complex\n",
    "        n = noiseSigma*(np.random.randn(1,L)+1j*np.random.randn(1,L))#computed noise \n",
    "    else:\n",
    "        noiseSigma = np.sqrt(N0);#Standard deviation for AWGN Noise when x is real\n",
    "        n = noiseSigma*np.random.randn(1,L)#computed noise\n",
    "    y = signal + n #received signal\n",
    "    return y.flatten()\n",
    "\n",
    "def num_bit_errs(in_bits, out_bits):\n",
    "    total = 0\n",
    "    for i in range(len(in_bits)):\n",
    "        if in_bits[i] != out_bits[i]:\n",
    "            total += 1\n",
    "    return total\n",
    "\n",
    "\n",
    "SIGNAL_LENGTH = 1000\n",
    "PREAMBLE_LENGTH = 100\n",
    "MOD_SCHEME = 'BPSK'\n",
    "CHANNEL_LENGTH = 3\n",
    "SNR = 5\n",
    "def generate_data(num, preamble_bits=None):\n",
    "    if preamble_bits is None:\n",
    "        preamble_bits = np.random.randint(0,2, PREAMBLE_LENGTH)\n",
    "    _p = []\n",
    "    _x = []\n",
    "    _y  = [] #\n",
    "    _pb = preamble_bits\n",
    "    _xb = [] #signal bits\n",
    "    _c = [] #channel taps\n",
    "    \n",
    "    for i in range(num):\n",
    "        # generate normalized channel function of consecutive taps\n",
    "        channel_function = np.random.randn(CHANNEL_LENGTH) \n",
    "        channel_function = channel_function / np.linalg.norm(channel_function)\n",
    "        _c.append(channel_function)\n",
    "        # generate preamble \n",
    "        train_preamble_noisy = add_awgn_noise(\n",
    "                            apply_channel(\n",
    "                                modulate(preamble_bits, MOD_SCHEME), \n",
    "                                channel_function),\n",
    "                            SNR) #len = PREAMBLE_LENGTH + CHANNEL_LENGTH-1\n",
    "        _p.append(train_preamble_noisy)\n",
    "        # generate message\n",
    "        train_signal_bits = np.random.randint(0,2, SIGNAL_LENGTH)\n",
    "        _xb.append(train_signal_bits)\n",
    "        train_signal = modulate(train_signal_bits, MOD_SCHEME) #len = SIGNAL_LENGTH\n",
    "        _y.append(train_signal)\n",
    "        train_signal_noisy = add_awgn_noise(apply_channel(train_signal, channel_function), SNR)#len = SIGNAL_LENGTH + CHANNEL_LENGTH-1 \n",
    "        _x.append(train_signal_noisy)\n",
    "    return np.array(_p), np.array(_x), np.array(_y), np.array(_pb), np.array(_xb), np.array(_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Activation\n",
    "import keras.layers as layers\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "NUM_ITERS = 100\n",
    "BATCH_SIZE = 100\n",
    "NUM_DATA = BATCH_SIZE * NUM_ITERS\n",
    "NUM_TEST = 1000\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "# Inputs\n",
    "preamble_input = Input(shape=(PREAMBLE_LENGTH+CHANNEL_LENGTH-1,), name='preamble')\n",
    "preamble_input = LSTM(50, return_sequences=True)(preamble_input)\n",
    "signal_input = Input(shape=(SIGNAL_LENGTH+CHANNEL_LENGTH-1,), name='signal')\n",
    "signal_input = LSTM(500, return_sequences=True)(signal_input)\n",
    "x = layers.concatenate([preamble_input, signal_input])\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "# Deep densely-connected network on top\n",
    "x = Dense(500, activation='sigmoid')(x)\n",
    "x = Dense(500, activation='sigmoid')(x)\n",
    "x = Dense(500, activation='sigmoid')(x)\n",
    "# Linear Layer\n",
    "signal_output = Dense(SIGNAL_LENGTH, activation='softmax', name='signal_output')(x)\n",
    "model = Model(inputs=[preamble_input, signal_input], outputs=[signal_output])\n",
    "\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = optimizers.Adam(lr=0.05, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, clipnorm=1.)\n",
    "def avg_bit_error(y_true, y_pred):\n",
    "    zeroes = K.zeros(shape=(K.int_shape(y_true)[1]))\n",
    "    return K.mean(K.cast(K.equal(K.greater(y_true, zeroes), K.greater(y_pred, zeroes)), dtype='float32'))\n",
    "\n",
    "def loss_fcn(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true-y_pred))\n",
    "\n",
    "model.compile(loss=loss_fcn, optimizer='adam', metrics=[avg_bit_error])\n",
    "\n",
    "preamble_train, signal_train, signal_output_train, preamble_bits, _, _, = generate_data(NUM_DATA, preamble_bits)\n",
    "model.fit({'preamble': preamble_train, 'signal': signal_train}, {'signal_output': signal_output_train.astype(float)}, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo:\n",
    "Add weight sharing: convolution\n",
    "more data\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
