{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import commpy as cp\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_size = 1\n",
    "learning_rate = 0.001\n",
    "# number of units in hidden layer\n",
    "num_hidden_units = 10\n",
    "\n",
    "# Lets start by working with the fft of our channel being real. \n",
    "training_inputs = np.random.rand(1000,channel_size)\n",
    "training_outputs = training_inputs\n",
    "\n",
    "# Validation inputs\n",
    "validation_inputs = np.random.rand(1000,channel_size)\n",
    "validation_outputs = validation_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost:  30556.1\n",
      "Cost:  15279.7\n",
      "Cost:  36353.9\n",
      "Cost:  17495.8\n",
      "Cost:  52422.9\n",
      "Cost:  17589.0\n",
      "Cost:  100061.0\n",
      "Cost:  38969.5\n",
      "Cost:  4854.79\n",
      "Cost:  28374.2\n",
      "Cost:  24877.8\n",
      "Cost:  50981.0\n",
      "Cost:  27058.3\n",
      "Cost:  52557.2\n",
      "Cost:  192.93\n",
      "Cost:  44237.1\n",
      "Cost:  28378.8\n",
      "Cost:  3346.25\n",
      "Cost:  19331.0\n",
      "Cost:  60006.3\n",
      "Cost:  25403.8\n",
      "Cost:  46364.4\n",
      "Cost:  32523.5\n",
      "Cost:  45242.1\n",
      "Cost:  27569.3\n",
      "Cost:  16850.6\n",
      "Cost:  -2409.12\n",
      "Cost:  -2470.67\n",
      "Cost:  31208.5\n",
      "Cost:  42415.0\n",
      "Cost:  39452.9\n",
      "Cost:  6756.44\n",
      "Cost:  2881.48\n",
      "Cost:  59481.6\n",
      "Cost:  84628.3\n",
      "Cost:  36388.1\n",
      "Cost:  37913.6\n",
      "Cost:  5010.81\n",
      "Cost:  22866.8\n",
      "Cost:  9877.54\n",
      "Cost:  48265.7\n",
      "Cost:  32483.1\n",
      "Cost:  -4172.39\n",
      "Cost:  14955.9\n",
      "Cost:  22923.7\n",
      "Cost:  38649.3\n",
      "Cost:  5876.75\n",
      "Cost:  46993.7\n",
      "Cost:  24145.0\n",
      "Cost:  -1169.42\n",
      "Cost:  49654.6\n",
      "Cost:  6578.78\n",
      "Cost:  36442.8\n",
      "Cost:  55645.5\n",
      "Cost:  16080.9\n",
      "Cost:  23475.6\n",
      "Cost:  117842.0\n",
      "Cost:  31045.5\n",
      "Cost:  21673.4\n",
      "Cost:  49253.9\n",
      "Cost:  13260.4\n",
      "Cost:  49090.3\n",
      "Cost:  54439.1\n",
      "Cost:  39276.5\n",
      "Cost:  47547.8\n",
      "Cost:  13069.0\n",
      "Cost:  102216.0\n",
      "Cost:  40927.7\n",
      "Cost:  49206.7\n",
      "Cost:  24911.1\n",
      "Cost:  19338.5\n",
      "Cost:  40759.3\n",
      "Cost:  38968.6\n",
      "Cost:  24200.2\n",
      "Cost:  83262.4\n",
      "Cost:  22374.1\n",
      "Cost:  11589.7\n",
      "Cost:  68713.0\n",
      "Cost:  6097.57\n",
      "Cost:  30321.2\n",
      "Cost:  -2186.44\n",
      "Cost:  69430.6\n",
      "Cost:  6399.98\n",
      "Cost:  20116.9\n",
      "Cost:  62104.4\n",
      "Cost:  23015.3\n",
      "Cost:  30734.1\n",
      "Cost:  8572.08\n",
      "Cost:  15768.5\n",
      "Cost:  12482.4\n",
      "Cost:  31243.9\n",
      "Cost:  36249.1\n",
      "Cost:  16736.7\n",
      "Cost:  43760.0\n",
      "Cost:  69510.9\n",
      "Cost:  96740.0\n",
      "Cost:  66759.5\n",
      "Cost:  27790.0\n",
      "Cost:  26257.3\n",
      "Cost:  17353.2\n"
     ]
    }
   ],
   "source": [
    "# placeholder for inputs and outputs\n",
    "seed = 128\n",
    "tf_inputs = tf.placeholder(tf.float32, shape=[None, channel_size])\n",
    "tf_outputs = tf.placeholder(tf.float32, shape=[None, channel_size])\n",
    "\n",
    "# initialize weights to be random\n",
    "weights = {\n",
    "    'hidden1': tf.Variable(tf.random_normal([channel_size, num_hidden_units], seed=seed)),\n",
    "    'hidden2': tf.Variable(tf.random_normal([num_hidden_units, num_hidden_units], seed=seed)),\n",
    "    'hidden3': tf.Variable(tf.random_normal([num_hidden_units, num_hidden_units], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([num_hidden_units, channel_size], seed=seed))\n",
    "}\n",
    "\n",
    "# initialize biases to be random\n",
    "biases = {\n",
    "    'hidden1': tf.Variable(tf.random_normal([num_hidden_units], seed=seed)),\n",
    "    'hidden2': tf.Variable(tf.random_normal([num_hidden_units], seed=seed)),\n",
    "    'hidden3': tf.Variable(tf.random_normal([num_hidden_units], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([channel_size]))\n",
    "}\n",
    "\n",
    "# create network layers\n",
    "hidden_layer1 = tf.add(tf.matmul(tf_inputs, weights['hidden1']), biases['hidden1'])\n",
    "hidden_layer1 = tf.nn.relu(hidden_layer1)\n",
    "#hidden_layer2 = tf.add(tf.matmul(hidden_layer1, weights['hidden2']), biases['hidden2'])\n",
    "#hidden_layer2 = tf.nn.relu(hidden_layer2)\n",
    "#hidden_layer3 = tf.add(tf.matmul(hidden_layer2, weights['hidden3']), biases['hidden3'])\n",
    "#hidden_layer3 = tf.nn.sigmoid(hidden_layer3)\n",
    "\n",
    "output_layer = tf.add(tf.matmul(hidden_layer1, weights['output']), biases['output'])\n",
    "#output_layer = tf.nn.sigmoid(output_layer)\n",
    "\n",
    "# create cost function\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output_layer, tf_outputs))\n",
    "cost = tf.reduce_sum(tf.subtract(output_layer,tf_outputs))#tf.nn.l2_loss(tf.subtract(output_layer,tf_outputs))\n",
    "\n",
    "# optimizer to do gradient descent\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    for i in range(100):\n",
    "        # Lets start by working with the fft of our channel being real. \n",
    "        training_inputs = np.random.rand(5000,channel_size)\n",
    "        training_outputs = training_inputs\n",
    "        \n",
    "        sess.run(init)\n",
    "        _, c = sess.run([optimizer, cost], \n",
    "                      feed_dict={tf_inputs: training_inputs, tf_outputs: training_outputs})\n",
    "        \n",
    "        print(\"Cost: \", c)\n",
    "\n",
    "    # find predictions\n",
    "    predictions = sess.run(output_layer, feed_dict={tf_inputs: validation_inputs})\n",
    "    predictions2 = sess.run(output_layer, feed_dict={tf_inputs: training_inputs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: \n",
      " [[ 3.87867188]\n",
      " [ 3.47505307]\n",
      " [ 3.89553142]\n",
      " [ 4.74938345]\n",
      " [ 5.06337166]\n",
      " [ 3.23114347]\n",
      " [ 2.73406529]\n",
      " [ 3.72823596]\n",
      " [ 2.82293677]\n",
      " [ 5.21777582]] \n",
      "\n",
      "Validation Inputs: \n",
      " [[ 0.47024785]\n",
      " [ 0.32819603]\n",
      " [ 0.47618158]\n",
      " [ 0.77669087]\n",
      " [ 0.88719759]\n",
      " [ 0.24235309]\n",
      " [ 0.06740866]\n",
      " [ 0.41730258]\n",
      " [ 0.09868659]\n",
      " [ 0.94153946]] \n",
      "\n",
      "Validation Desired output\n",
      " [[ 0.47024785]\n",
      " [ 0.32819603]\n",
      " [ 0.47618158]\n",
      " [ 0.77669087]\n",
      " [ 0.88719759]\n",
      " [ 0.24235309]\n",
      " [ 0.06740866]\n",
      " [ 0.41730258]\n",
      " [ 0.09868659]\n",
      " [ 0.94153946]] \n",
      "\n",
      "Predictions: \n",
      " [[ 3.00878644]\n",
      " [ 2.98254204]\n",
      " [ 2.92164159]\n",
      " [ 3.69230676]\n",
      " [ 3.25115538]\n",
      " [ 3.25847697]\n",
      " [ 4.15027714]\n",
      " [ 4.79872131]\n",
      " [ 2.6231184 ]\n",
      " [ 3.54049897]] \n",
      "\n",
      "Training Inputs: \n",
      " [[ 0.16409555]\n",
      " [ 0.15485893]\n",
      " [ 0.13342536]\n",
      " [ 0.40465756]\n",
      " [ 0.24939623]\n",
      " [ 0.25197301]\n",
      " [ 0.56583798]\n",
      " [ 0.79405506]\n",
      " [ 0.02836134]\n",
      " [ 0.35122943]] \n",
      "\n",
      "Training Desired output\n",
      " [[ 0.16409555]\n",
      " [ 0.15485893]\n",
      " [ 0.13342536]\n",
      " [ 0.40465756]\n",
      " [ 0.24939623]\n",
      " [ 0.25197301]\n",
      " [ 0.56583798]\n",
      " [ 0.79405506]\n",
      " [ 0.02836134]\n",
      " [ 0.35122943]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing predictions \n",
    "i = 89\n",
    "print(\"Predictions: \\n\", predictions[i:i+10], '\\n')\n",
    "print(\"Validation Inputs: \\n\", validation_inputs[i:i+10], '\\n')\n",
    "print(\"Validation Desired output\\n\", validation_outputs[i:i+10], '\\n')\n",
    "\n",
    "print(\"Predictions: \\n\", predictions2[i:i+10], '\\n')\n",
    "print(\"Training Inputs: \\n\", training_inputs[i:i+10], '\\n')\n",
    "print(\"Training Desired output\\n\", training_outputs[i:i+10], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
